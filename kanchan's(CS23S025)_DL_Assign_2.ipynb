{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART-A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T12:38:54.731001Z",
     "iopub.status.busy": "2025-04-19T12:38:54.730727Z",
     "iopub.status.idle": "2025-04-19T12:38:54.735188Z",
     "shell.execute_reply": "2025-04-19T12:38:54.734653Z",
     "shell.execute_reply.started": "2025-04-19T12:38:54.730979Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import wandb\n",
    "# wandb.login(key = \"b4dc866a06ba17317c20de0d13c1a64cc23096dd\")\n",
    "# ENTITY = \"cs23s025-indian-institute-of-technology-madras\"  \n",
    "# PROJECT = \"CS23S025-Assignment-2-DL\"  \n",
    "# API = wandb.Api()\n",
    "\n",
    "\n",
    "# runs = API.runs(f\"{ENTITY}/{PROJECT}\")\n",
    "# sweep_dict = {}\n",
    "\n",
    "# for run in runs:\n",
    "#     if run.sweep:  # Check if the run belongs to a sweep\n",
    "#         sweep_id = run.sweep.id\n",
    "#         sweep_name = run.sweep.config.get(\"name\", \"Unnamed Sweep\")\n",
    "#         sweep_dict[sweep_id] = sweep_name\n",
    "\n",
    "# for sweep_id, sweep_name in sweep_dict.items():\n",
    "#     print(f\"Sweep Name: {sweep_name}, Sweep ID: {sweep_id}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T12:38:54.740747Z",
     "iopub.status.busy": "2025-04-19T12:38:54.740538Z",
     "iopub.status.idle": "2025-04-19T12:40:14.143540Z",
     "shell.execute_reply": "2025-04-19T12:40:14.142952Z",
     "shell.execute_reply.started": "2025-04-19T12:38:54.740731Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightning\n",
      "  Downloading lightning-2.5.1-py3-none-any.whl.metadata (39 kB)\n",
      "Requirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.11/dist-packages (from lightning) (6.0.2)\n",
      "Requirement already satisfied: fsspec<2026.0,>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (2025.3.2)\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (0.14.3)\n",
      "Requirement already satisfied: packaging<25.0,>=20.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (24.2)\n",
      "Requirement already satisfied: torch<4.0,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (2.5.1+cu124)\n",
      "Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (1.7.1)\n",
      "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (4.13.1)\n",
      "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.11/dist-packages (from lightning) (2.5.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (3.11.16)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning) (75.1.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.18.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.4.127)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<4.0,>=2.1.0->lightning)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<4.0,>=2.1.0->lightning)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<4.0,>=2.1.0->lightning)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<4.0,>=2.1.0->lightning)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<4.0,>=2.1.0->lightning)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<4.0,>=2.1.0->lightning)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<4.0,>=2.1.0->lightning)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<4.0,>=2.1.0->lightning) (1.3.0)\n",
      "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics<3.0,>=0.7.0->lightning) (1.26.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.19.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>1.20.0->torchmetrics<3.0,>=0.7.0->lightning) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>1.20.0->torchmetrics<3.0,>=0.7.0->lightning) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>1.20.0->torchmetrics<3.0,>=0.7.0->lightning) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>1.20.0->torchmetrics<3.0,>=0.7.0->lightning) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>1.20.0->torchmetrics<3.0,>=0.7.0->lightning) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>1.20.0->torchmetrics<3.0,>=0.7.0->lightning) (2.4.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<4.0,>=2.1.0->lightning) (3.0.2)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (3.10)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>1.20.0->torchmetrics<3.0,>=0.7.0->lightning) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>1.20.0->torchmetrics<3.0,>=0.7.0->lightning) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>1.20.0->torchmetrics<3.0,>=0.7.0->lightning) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>1.20.0->torchmetrics<3.0,>=0.7.0->lightning) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>1.20.0->torchmetrics<3.0,>=0.7.0->lightning) (2024.2.0)\n",
      "Downloading lightning-2.5.1-py3-none-any.whl (818 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m818.9/818.9 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, lightning\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.9.90\n",
      "    Uninstalling nvidia-curand-cu12-10.3.9.90:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n",
      "    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n",
      "    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed lightning-2.5.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs23s025\u001b[0m (\u001b[33mcs23s025-indian-institute-of-technology-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install lightning\n",
    "import wandb\n",
    "\n",
    "wandb.login(key = \"b4dc866a06ba17317c20de0d13c1a64cc23096dd\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-04-19T12:40:14.145285Z",
     "iopub.status.busy": "2025-04-19T12:40:14.144962Z",
     "iopub.status.idle": "2025-04-19T12:40:25.797731Z",
     "shell.execute_reply": "2025-04-19T12:40:25.797186Z",
     "shell.execute_reply.started": "2025-04-19T12:40:14.145267Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import lightning.pytorch as L\n",
    "\n",
    "\n",
    "class convNet(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        img_size,\n",
    "        activation,\n",
    "        num_filters,\n",
    "        filter_size,\n",
    "        filter_org,\n",
    "        stride,\n",
    "        padding,\n",
    "        dense_neurons,\n",
    "        learning_rate,\n",
    "        optimizer,\n",
    "        dropout,\n",
    "        usedropout,\n",
    "        batchnorm,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # self.img_size = img_size\n",
    "        self.activation = activation\n",
    "        self.num_filters = num_filters\n",
    "        self.kernel_size = filter_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.dense_neurons = dense_neurons\n",
    "        self.lr = learning_rate\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.usedropout = usedropout\n",
    "        self.batchnorm = batchnorm\n",
    "\n",
    "        # Define convolutional layers\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=3,\n",
    "            out_channels=self.num_filters,\n",
    "            kernel_size=self.kernel_size,\n",
    "            stride=self.stride,\n",
    "            padding=self.padding,\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=self.num_filters)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=self.num_filters,\n",
    "            out_channels=self.num_filters * filter_org,\n",
    "            kernel_size=self.kernel_size,\n",
    "            stride=self.stride,\n",
    "            padding=self.padding,\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=self.conv2.out_channels)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            in_channels=self.conv2.out_channels,\n",
    "            out_channels=self.conv2.out_channels * filter_org,\n",
    "            kernel_size=self.kernel_size,\n",
    "            stride=self.stride,\n",
    "            padding=self.padding,\n",
    "        )\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=self.conv3.out_channels)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(\n",
    "            in_channels=self.conv3.out_channels,\n",
    "            out_channels=self.num_filters * filter_org,\n",
    "            kernel_size=self.kernel_size,\n",
    "            stride=self.stride,\n",
    "            padding=self.padding,\n",
    "        )\n",
    "        self.bn4 = nn.BatchNorm2d(num_features=self.conv4.out_channels)\n",
    "\n",
    "        self.conv5 = nn.Conv2d(\n",
    "            in_channels=self.conv4.out_channels,\n",
    "            out_channels=self.num_filters * filter_org,\n",
    "            kernel_size=self.kernel_size,\n",
    "            stride=self.stride,\n",
    "            padding=self.padding,\n",
    "        )\n",
    "        self.bn5 = nn.BatchNorm2d(num_features=self.conv5.out_channels)\n",
    "\n",
    "        # Define activation function based on user input\n",
    "        if self.activation.lower() == \"relu\":\n",
    "            self.activation_layer = nn.ReLU()\n",
    "        elif self.activation.lower() == \"gelu\":\n",
    "            self.activation_layer = nn.GELU()\n",
    "        elif self.activation.lower() == \"silu\":\n",
    "            self.activation_layer = nn.SiLU()\n",
    "        elif self.activation.lower() == \"mish\":\n",
    "            self.activation_layer = nn.Mish()\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Invalid activation function. Choose from 'relu', 'gelu', 'mish' or 'silu'\"\n",
    "            )\n",
    "\n",
    "        # Define max-pooling layers\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.dropout_layer = nn.Dropout(p=dropout)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        c1s = int(\n",
    "            (((img_size - self.kernel_size + (2 * self.padding)) / self.stride) + 1) / 2\n",
    "        )\n",
    "\n",
    "        c2s = int(\n",
    "            (((c1s - self.kernel_size + (2 * self.padding)) / self.stride) + 1) / 2\n",
    "        )\n",
    "\n",
    "        c3s = int(\n",
    "            (((c2s - self.kernel_size + (2 * self.padding)) / self.stride) + 1) / 2\n",
    "        )\n",
    "\n",
    "        c4s = int(\n",
    "            (((c3s - self.kernel_size + (2 * self.padding)) / self.stride) + 1) / 2\n",
    "        )\n",
    "\n",
    "        c5s = int(\n",
    "            (((c4s - self.kernel_size + (2 * self.padding)) / self.stride) + 1) / 2\n",
    "        )\n",
    "\n",
    "        # print(f\"c1s_{c1s}_c2s_{c2s}_c3s_{c3s}_c4s_{c4s}_c5s_{c5s}_out_{self.conv5.out_channels}\")\n",
    "\n",
    "        flatten_neurons = int(c5s * c5s * self.conv5.out_channels)\n",
    "\n",
    "        # print(f\"multi_{c5s*c5s*self.conv5.out_channels}_flat_{flatten_neurons}\")\n",
    "\n",
    "        # Define fully connected layers\n",
    "        self.fc1 = nn.Linear(flatten_neurons, dense_neurons)\n",
    "        self.fc2 = nn.Linear(dense_neurons, 10)\n",
    "        self.softmax_layer = nn.Softmax()\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Convolutional layers\n",
    "        x = self.conv1(x)\n",
    "        if self.batchnorm == \"Y\":\n",
    "            x = self.bn1(x)\n",
    "        x = self.activation_layer(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        if self.batchnorm == \"Y\":\n",
    "            x = self.bn2(x)\n",
    "        x = self.activation_layer(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        if self.usedropout == \"Y\":\n",
    "            x = self.dropout_layer(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        if self.batchnorm == \"Y\":\n",
    "            x = self.bn3(x)\n",
    "        x = self.activation_layer(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        if self.usedropout == \"Y\":\n",
    "            x = self.dropout_layer(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        if self.batchnorm == \"Y\":\n",
    "            x = self.bn4(x)\n",
    "        x = self.activation_layer(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        if self.usedropout == \"Y\":\n",
    "            x = self.dropout_layer(x)\n",
    "\n",
    "        x = self.conv5(x)\n",
    "        if self.batchnorm == \"Y\":\n",
    "            x = self.bn5(x)\n",
    "        x = self.activation_layer(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        # Flatten\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        if self.usedropout == \"Y\":\n",
    "            x = self.dropout_layer(x)\n",
    "\n",
    "        # Fully connected layers\n",
    "        x = self.fc1(x)\n",
    "        x = self.activation_layer(x)\n",
    "        x = self.fc2(x)\n",
    "        # x = self.softmax_layer(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, scores, y, accuracy = self._common_step(batch, batch_idx)\n",
    "\n",
    "        self.log_dict(\n",
    "            {\"train_loss\": loss, \"train_accuracy\": accuracy},\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "        )\n",
    "        return {\"loss\": loss, \"scores\": scores, \"y\": y}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, _, _, accuracy = self._common_step(batch, batch_idx)\n",
    "        self.log_dict(\n",
    "            {\"validation_loss\": loss, \"validation_accuracy\": accuracy},\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, scores, y, accuracy = self._common_step(batch, batch_idx)\n",
    "\n",
    "        self.log_dict(\n",
    "            {\"test_loss\": loss, \"test_accuracy\": accuracy},\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    def _common_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "\n",
    "        accuracy = 0\n",
    "\n",
    "        scores = self.forward(x)\n",
    "        loss = self.loss_fn(scores, y)\n",
    "        y_pred = torch.argmax(torch.softmax(scores, dim=1), dim=1)\n",
    "        accuracy += (y_pred == y).sum().item()\n",
    "        accuracy = accuracy / len(scores)\n",
    "        return loss, scores, y, accuracy\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "\n",
    "        scores = self.forward(x)\n",
    "        preds = torch.argmax(scores, dim=1)\n",
    "        return preds\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        if self.optimizer.lower() == \"adam\":\n",
    "\n",
    "            return optim.Adam(self.parameters(), lr=self.lr)\n",
    "\n",
    "        elif self.optimizer.lower() == \"sgd\":\n",
    "\n",
    "            return optim.SGD(self.parameters(), lr=self.lr)\n",
    "\n",
    "        elif self.optimizer.lower() == \"nadam\":\n",
    "\n",
    "            return optim.NAdam(self.parameters(), lr=self.lr)\n",
    "\n",
    "        elif self.optimizer.lower() == \"rmsprop\":\n",
    "\n",
    "            return optim.RMSprop(self.parameters(), lr=self.lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T12:40:25.798724Z",
     "iopub.status.busy": "2025-04-19T12:40:25.798359Z",
     "iopub.status.idle": "2025-04-19T12:40:25.808628Z",
     "shell.execute_reply": "2025-04-19T12:40:25.807958Z",
     "shell.execute_reply.started": "2025-04-19T12:40:25.798705Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import lightning.pytorch as L\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "class iNaturalistDataModule(L.LightningDataModule):\n",
    "    def __init__(self, data_dir, batch_size, num_workers, img_size, data_augmentation):\n",
    "        super().__init__()\n",
    "\n",
    "        self.train_path = data_dir / \"train\"\n",
    "        self.test_path = data_dir / \"val\"\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "        if data_augmentation == \"Y\":\n",
    "\n",
    "            self.data_transform = transforms.Compose(\n",
    "                [\n",
    "                    transforms.Resize(size=(img_size, img_size)),\n",
    "                    transforms.AutoAugment(),  # This is the data augmentation method chosen\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(\n",
    "                        mean=[0.4712, 0.4600, 0.3896], std=[0.2034, 0.1981, 0.1948]\n",
    "                    ),  # These values are calculated for our dataset\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        elif data_augmentation == \"N\":\n",
    "\n",
    "            self.data_transform = transforms.Compose(\n",
    "                [\n",
    "                    transforms.Resize(size=(img_size, img_size)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(\n",
    "                        mean=[0.4712, 0.4600, 0.3896], std=[0.2034, 0.1981, 0.1948]\n",
    "                    ),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        self.test_data_transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize(size=(img_size, img_size)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(\n",
    "                    mean=[0.4748, 0.4645, 0.3965], std=[0.2004, 0.1954, 0.1923]\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def setup(self, stage):\n",
    "        if stage == \"fit\":\n",
    "\n",
    "            # First load all the training data\n",
    "            train_data_full = datasets.ImageFolder(\n",
    "                root=self.train_path,\n",
    "                transform=self.data_transform,\n",
    "                target_transform=None,\n",
    "            )\n",
    "\n",
    "            # Decide the number of validation samples required\n",
    "            validation_samples_per_class = int(0.2 * 1000)\n",
    "\n",
    "            # These lists will hold the indices of training and validation data samples\n",
    "            train_indices = []\n",
    "            val_indices = []\n",
    "\n",
    "            for class_idx in range(len(train_data_full.classes)):\n",
    "\n",
    "                # Obtain the indices of each class\n",
    "                class_indices = [\n",
    "                    idx\n",
    "                    for idx, (_, label) in enumerate(train_data_full.imgs)\n",
    "                    if label == class_idx\n",
    "                ]\n",
    "\n",
    "                # Split and add the indices to the respective lists\n",
    "                val_indices.extend(class_indices[:validation_samples_per_class])\n",
    "                train_indices.extend(class_indices[validation_samples_per_class:])\n",
    "\n",
    "            # Create a two subsets of the initially loaded training data as training data and validation data\n",
    "            self.train_data = Subset(train_data_full, train_indices)\n",
    "            self.val_data = Subset(train_data_full, val_indices)\n",
    "\n",
    "        if stage == \"test\":\n",
    "            # Load the test data\n",
    "            self.test_data = datasets.ImageFolder(\n",
    "                root=self.test_path, transform=self.test_data_transform\n",
    "            )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_data,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            persistent_workers=True,\n",
    "            shuffle=True,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_data,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            persistent_workers=True,\n",
    "            shuffle=False,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_data,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=False,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T12:40:25.810794Z",
     "iopub.status.busy": "2025-04-19T12:40:25.810584Z",
     "iopub.status.idle": "2025-04-19T12:40:25.833878Z",
     "shell.execute_reply": "2025-04-19T12:40:25.833252Z",
     "shell.execute_reply.started": "2025-04-19T12:40:25.810776Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class wandbconfig:\n",
    "\n",
    "    def set_configs(args):\n",
    "\n",
    "        wandb_configs = {\n",
    "            \"epochs\": args.epochs,\n",
    "            \"img_size\": args.img_size,\n",
    "            \"dataug\": args.dataug,\n",
    "            \"batchnorm\": args.batchnorm,\n",
    "            \"num_filters\": args.num_filters,\n",
    "            \"filter_size\": args.filter_size,\n",
    "            \"filter_org\": args.filter_org,\n",
    "            \"batch_size\": args.batch_size,\n",
    "            \"learning_rate\": args.learning_rate,\n",
    "            \"dropout\": args.dropout,\n",
    "            \"usedropout\": args.usedropout,\n",
    "            \"optimizer\": args.optimizer,\n",
    "            \"dense_neurons\": args.dense_neurons,\n",
    "            \"activation\": args.activation,\n",
    "            \"stride\": args.stride,\n",
    "            \"padding\": args.padding,\n",
    "        }\n",
    "\n",
    "        return wandb_configs\n",
    "\n",
    "    def run_name(wandb_configs):\n",
    "\n",
    "        run_name = \"nf_{}_fsz_{}_fo_{}_a_{}_e_{}_b_{}_dn_{}_da_{}\".format(\n",
    "            wandb_configs[\"num_filters\"],\n",
    "            wandb_configs[\"filter_size\"],\n",
    "            wandb_configs[\"filter_org\"],\n",
    "            wandb_configs[\"activation\"],\n",
    "            wandb_configs[\"epochs\"],\n",
    "            wandb_configs[\"batch_size\"],\n",
    "            wandb_configs[\"dense_neurons\"],\n",
    "            wandb_configs[\"dataug\"],\n",
    "        )\n",
    "\n",
    "        return run_name\n",
    "\n",
    "    def sweep_name(wandb_configs):\n",
    "\n",
    "        sweep_name = \"nf_{}_fsz_{}_fo_{}_a_{}_e_{}_b_{}_dn_{}\".format(\n",
    "            wandb_configs.num_filters,\n",
    "            wandb_configs.filter_size,\n",
    "            wandb_configs.filter_org,\n",
    "            wandb_configs.activation,\n",
    "            wandb_configs.epochs,\n",
    "            wandb_configs.batch_size,\n",
    "            wandb_configs.dense_neurons,\n",
    "        )\n",
    "\n",
    "        return sweep_name\n",
    "\n",
    "    def tuner_set_configs(args):\n",
    "\n",
    "        wandb_configs = {\n",
    "            \"epochs\": args.epochs,\n",
    "            \"img_size\": args.img_size,\n",
    "            \"batch_size\": args.batch_size,\n",
    "            \"learning_rate\": args.learning_rate,\n",
    "            \"dropout\": args.dropout,\n",
    "        }\n",
    "\n",
    "        return wandb_configs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T12:40:25.834995Z",
     "iopub.status.busy": "2025-04-19T12:40:25.834746Z",
     "iopub.status.idle": "2025-04-19T13:04:10.825013Z",
     "shell.execute_reply": "2025-04-19T13:04:10.824209Z",
     "shell.execute_reply.started": "2025-04-19T12:40:25.834971Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: jjtcz9g6\n",
      "Sweep URL: https://wandb.ai/cs23s025-indian-institute-of-technology-madras/CS23S025-Assignment-2-DL/sweeps/jjtcz9g6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3gvof987 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: gelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchnorm: Y\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdataug: N\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_neurons: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_org: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \timg_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpadding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tstride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tusedropout: Y\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'CS23S025-Assignment-2-DL' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Ignoring entity 'cs23s025-indian-institute-of-technology-madras' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250419_124032-3gvof987</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cs23s025-indian-institute-of-technology-madras/CS23S025-Assignment-2-DL/runs/3gvof987' target=\"_blank\">wobbly-sweep-1</a></strong> to <a href='https://wandb.ai/cs23s025-indian-institute-of-technology-madras/CS23S025-Assignment-2-DL' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs23s025-indian-institute-of-technology-madras/CS23S025-Assignment-2-DL/sweeps/jjtcz9g6' target=\"_blank\">https://wandb.ai/cs23s025-indian-institute-of-technology-madras/CS23S025-Assignment-2-DL/sweeps/jjtcz9g6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cs23s025-indian-institute-of-technology-madras/CS23S025-Assignment-2-DL' target=\"_blank\">https://wandb.ai/cs23s025-indian-institute-of-technology-madras/CS23S025-Assignment-2-DL</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/cs23s025-indian-institute-of-technology-madras/CS23S025-Assignment-2-DL/sweeps/jjtcz9g6' target=\"_blank\">https://wandb.ai/cs23s025-indian-institute-of-technology-madras/CS23S025-Assignment-2-DL/sweeps/jjtcz9g6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cs23s025-indian-institute-of-technology-madras/CS23S025-Assignment-2-DL/runs/3gvof987' target=\"_blank\">https://wandb.ai/cs23s025-indian-institute-of-technology-madras/CS23S025-Assignment-2-DL/runs/3gvof987</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: GPU available: True (cuda), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "/usr/local/lib/python3.11/dist-packages/lightning/pytorch/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO: \n",
      "   | Name             | Type             | Params | Mode \n",
      "---------------------------------------------------------------\n",
      "0  | loss_fn          | CrossEntropyLoss | 0      | train\n",
      "1  | conv1            | Conv2d           | 1.8 K  | train\n",
      "2  | bn1              | BatchNorm2d      | 128    | train\n",
      "3  | conv2            | Conv2d           | 73.9 K | train\n",
      "4  | bn2              | BatchNorm2d      | 256    | train\n",
      "5  | conv3            | Conv2d           | 295 K  | train\n",
      "6  | bn3              | BatchNorm2d      | 512    | train\n",
      "7  | conv4            | Conv2d           | 295 K  | train\n",
      "8  | bn4              | BatchNorm2d      | 256    | train\n",
      "9  | conv5            | Conv2d           | 147 K  | train\n",
      "10 | bn5              | BatchNorm2d      | 256    | train\n",
      "11 | activation_layer | GELU             | 0      | train\n",
      "12 | pool             | MaxPool2d        | 0      | train\n",
      "13 | dropout_layer    | Dropout          | 0      | train\n",
      "14 | flatten          | Flatten          | 0      | train\n",
      "15 | fc1              | Linear           | 524 K  | train\n",
      "16 | fc2              | Linear           | 650    | train\n",
      "17 | softmax_layer    | Softmax          | 0      | train\n",
      "---------------------------------------------------------------\n",
      "1.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 M     Total params\n",
      "5.359     Total estimated model params size (MB)\n",
      "18        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0da4526cfd94d978d0c6e0d079abb29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: `Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bc1bb155e774b3193d79c8f42370cb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    validation_accuracy    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.39399999380111694    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      validation_loss      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    2.0338504314422607     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m   validation_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.39399999380111694   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     validation_loss     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   2.0338504314422607    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model path: /kaggle/working/output/best_model.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>train_accuracy</td><td>▁▂▂▃▃▃▄▄▄▄▅▅▅▆▆▆▇▇██</td></tr><tr><td>train_loss</td><td>█▇▇▆▆▆▅▅▅▅▄▄▄▃▃▃▂▂▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>validation_accuracy</td><td>▁▃▄▄▅▅▆▆▆▆▆▇▇▇███▇▇██</td></tr><tr><td>validation_loss</td><td>█▆▄▅▃▃▂▂▂▂▃▂▁▃▂▃▂▅▆▆▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>20</td></tr><tr><td>train_accuracy</td><td>0.66358</td></tr><tr><td>train_loss</td><td>0.94918</td></tr><tr><td>trainer/global_step</td><td>2500</td></tr><tr><td>validation_accuracy</td><td>0.394</td></tr><tr><td>validation_loss</td><td>2.03385</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">nf_64_fsz_3_fo_2_a_gelu_e_20_b_64_dn_64</strong> at: <a href='https://wandb.ai/cs23s025-indian-institute-of-technology-madras/CS23S025-Assignment-2-DL/runs/3gvof987' target=\"_blank\">https://wandb.ai/cs23s025-indian-institute-of-technology-madras/CS23S025-Assignment-2-DL/runs/3gvof987</a><br> View project at: <a href='https://wandb.ai/cs23s025-indian-institute-of-technology-madras/CS23S025-Assignment-2-DL' target=\"_blank\">https://wandb.ai/cs23s025-indian-institute-of-technology-madras/CS23S025-Assignment-2-DL</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250419_124032-3gvof987/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import wandb\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.fabric.utilities.seed import seed_everything\n",
    "from pathlib import Path\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "#from convolutional import convNet\n",
    "#from dataset import iNaturalistDataModule\n",
    "#from wandbConfigs import wandbconfig\n",
    "\n",
    "device = \"gpu\" if torch.cuda.is_available() else \"cpu\"\n",
    "seed_everything(42)\n",
    "sweep_configs = {\n",
    "    \"name\": \"MAX Acc\",\n",
    "    \"metric\": {\"name\": \"validation_accuracy\", \"goal\": \"maximize\"},\n",
    "    \"method\": \"bayes\",\n",
    "    \"early_terminate\": {\"type\": \"hyperband\", \"min_iter\": 4, \"eta\": 2},\n",
    "    \"parameters\": {\n",
    "        \"img_size\": {\"values\": [256]},\n",
    "        \"num_filters\": {\"values\": [64]},\n",
    "        \"filter_size\": {\"values\": [3]},\n",
    "        \"filter_org\": {\"values\": [2]},\n",
    "        \"activation\": {\"values\": [\"gelu\"]},\n",
    "        \"optimizer\": {\"values\": [\"adam\"]},\n",
    "        \"epochs\": {\"values\": [20]},\n",
    "        \"batch_size\": {\"values\": [64]},\n",
    "        \"learning_rate\": {\"values\": [0.001]},\n",
    "        \"dataug\": {\"values\": [\"N\"]},\n",
    "        \"dense_neurons\": {\"values\": [64]},\n",
    "        \"batchnorm\": {\"values\": [\"Y\"]},\n",
    "        \"stride\": {\"values\": [1]},\n",
    "        \"padding\": {\"values\": [1]},\n",
    "        \"dropout\": {\"values\": [0.1]},\n",
    "        \"usedropout\": {\"values\": [\"Y\"]},\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "hyperparameter_defaults = dict()\n",
    "\n",
    "\n",
    "def train():\n",
    "\n",
    "    # Initialise wandb\n",
    "\n",
    "    wandb.init(\n",
    "        config=hyperparameter_defaults, project=\"CS23S025-Assignment-2-DL\", \n",
    "        entity=\"cs23s025-indian-institute-of-technology-madras\"\n",
    "    )\n",
    "    wandb_logger = WandbLogger(project=\"CS23S025-Assignment-2-DL\")\n",
    "    wandb_configs = wandb.config\n",
    "\n",
    "    sweep_name = wandbconfig.sweep_name(wandb_configs)\n",
    "\n",
    "    wandb.run.name = sweep_name\n",
    "\n",
    "    model = convNet(\n",
    "        img_size=wandb_configs.img_size,\n",
    "        activation=wandb_configs.activation,\n",
    "        num_filters=wandb_configs.num_filters,\n",
    "        filter_size=wandb_configs.filter_size,\n",
    "        filter_org=wandb_configs.filter_org,\n",
    "        stride=wandb_configs.stride,\n",
    "        padding=wandb_configs.padding,\n",
    "        dense_neurons=wandb_configs.dense_neurons,\n",
    "        learning_rate=wandb_configs.learning_rate,\n",
    "        optimizer=wandb_configs.optimizer,\n",
    "        dropout=wandb_configs.dropout,\n",
    "        usedropout=wandb_configs.usedropout,\n",
    "        batchnorm=wandb_configs.batchnorm,\n",
    "    )\n",
    "\n",
    "    data = iNaturalistDataModule(\n",
    "        data_dir=Path(\"/kaggle/input/naturenew/inaturalist_12K\"),\n",
    "        batch_size=wandb_configs.batch_size,\n",
    "        num_workers=2,\n",
    "        img_size=wandb_configs.img_size,\n",
    "        data_augmentation=wandb_configs.dataug,\n",
    "    )\n",
    "    \n",
    "    #\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"validation_accuracy\",\n",
    "    mode=\"max\",\n",
    "    save_top_k=1,\n",
    "    dirpath=\"/kaggle/working/output/\",\n",
    "    filename=\"best_model\",\n",
    "    save_weights_only=False  # Save full model\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        accelerator=device,\n",
    "        callbacks=[checkpoint_callback],\n",
    "        min_epochs=1,\n",
    "        max_epochs=wandb_configs.epochs,\n",
    "        logger=wandb_logger,\n",
    "        log_every_n_steps=50,\n",
    "         \n",
    "    )\n",
    "    #trainer.fit(model, data)\n",
    "    trainer.fit(model, datamodule=data)\n",
    "    trainer.validate(model, data)\n",
    "    #trainer.test(model, data)\n",
    "    print(\"Best model path:\", checkpoint_callback.best_model_path)\n",
    "    best_model_path = checkpoint_callback.best_model_path\n",
    "   \n",
    "    wandb.finish()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    sweep_id = wandb.sweep(sweep_configs,\n",
    "                           entity=\"cs23s025-indian-institute-of-technology-madras\",\n",
    "                           project=\"CS23S025-Assignment-2-DL\")\n",
    "    wandb.agent(sweep_id, function=train,count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T15:34:43.901638Z",
     "iopub.status.busy": "2025-04-19T15:34:43.901036Z",
     "iopub.status.idle": "2025-04-19T15:34:47.231348Z",
     "shell.execute_reply": "2025-04-19T15:34:47.230448Z",
     "shell.execute_reply.started": "2025-04-19T15:34:43.901612Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightning in /usr/local/lib/python3.11/dist-packages (2.5.1)\n",
      "Requirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.11/dist-packages (from lightning) (6.0.2)\n",
      "Requirement already satisfied: fsspec<2026.0,>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (2025.3.2)\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (0.14.3)\n",
      "Requirement already satisfied: packaging<25.0,>=20.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (24.2)\n",
      "Requirement already satisfied: torch<4.0,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (2.5.1+cu124)\n",
      "Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (1.7.1)\n",
      "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (4.13.1)\n",
      "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.11/dist-packages (from lightning) (2.5.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (3.11.16)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning) (75.1.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.18.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<4.0,>=2.1.0->lightning) (1.3.0)\n",
      "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics<3.0,>=0.7.0->lightning) (1.26.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.19.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>1.20.0->torchmetrics<3.0,>=0.7.0->lightning) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>1.20.0->torchmetrics<3.0,>=0.7.0->lightning) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>1.20.0->torchmetrics<3.0,>=0.7.0->lightning) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>1.20.0->torchmetrics<3.0,>=0.7.0->lightning) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>1.20.0->torchmetrics<3.0,>=0.7.0->lightning) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>1.20.0->torchmetrics<3.0,>=0.7.0->lightning) (2.4.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<4.0,>=2.1.0->lightning) (3.0.2)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (3.10)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>1.20.0->torchmetrics<3.0,>=0.7.0->lightning) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>1.20.0->torchmetrics<3.0,>=0.7.0->lightning) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>1.20.0->torchmetrics<3.0,>=0.7.0->lightning) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>1.20.0->torchmetrics<3.0,>=0.7.0->lightning) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>1.20.0->torchmetrics<3.0,>=0.7.0->lightning) (2024.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install lightning\n",
    "import wandb\n",
    "\n",
    "wandb.login(key = \"b4dc866a06ba17317c20de0d13c1a64cc23096dd\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T15:34:47.233119Z",
     "iopub.status.busy": "2025-04-19T15:34:47.232885Z",
     "iopub.status.idle": "2025-04-19T15:34:48.769598Z",
     "shell.execute_reply": "2025-04-19T15:34:48.769010Z",
     "shell.execute_reply.started": "2025-04-19T15:34:47.233099Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import lightning.pytorch as L\n",
    "\n",
    "\n",
    "class convNet(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        img_size,\n",
    "        activation,\n",
    "        num_filters,\n",
    "        filter_size,\n",
    "        filter_org,\n",
    "        stride,\n",
    "        padding,\n",
    "        dense_neurons,\n",
    "        learning_rate,\n",
    "        optimizer,\n",
    "        dropout,\n",
    "        usedropout,\n",
    "        batchnorm,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # self.img_size = img_size\n",
    "        self.activation = activation\n",
    "        self.num_filters = num_filters\n",
    "        self.kernel_size = filter_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.dense_neurons = dense_neurons\n",
    "        self.lr = learning_rate\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.usedropout = usedropout\n",
    "        self.batchnorm = batchnorm\n",
    "\n",
    "        # Define convolutional layers\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=3,\n",
    "            out_channels=self.num_filters,\n",
    "            kernel_size=self.kernel_size,\n",
    "            stride=self.stride,\n",
    "            padding=self.padding,\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=self.num_filters)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=self.num_filters,\n",
    "            out_channels=self.num_filters * filter_org,\n",
    "            kernel_size=self.kernel_size,\n",
    "            stride=self.stride,\n",
    "            padding=self.padding,\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=self.conv2.out_channels)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            in_channels=self.conv2.out_channels,\n",
    "            out_channels=self.conv2.out_channels * filter_org,\n",
    "            kernel_size=self.kernel_size,\n",
    "            stride=self.stride,\n",
    "            padding=self.padding,\n",
    "        )\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=self.conv3.out_channels)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(\n",
    "            in_channels=self.conv3.out_channels,\n",
    "            out_channels=self.num_filters * filter_org,\n",
    "            kernel_size=self.kernel_size,\n",
    "            stride=self.stride,\n",
    "            padding=self.padding,\n",
    "        )\n",
    "        self.bn4 = nn.BatchNorm2d(num_features=self.conv4.out_channels)\n",
    "\n",
    "        self.conv5 = nn.Conv2d(\n",
    "            in_channels=self.conv4.out_channels,\n",
    "            out_channels=self.num_filters * filter_org,\n",
    "            kernel_size=self.kernel_size,\n",
    "            stride=self.stride,\n",
    "            padding=self.padding,\n",
    "        )\n",
    "        self.bn5 = nn.BatchNorm2d(num_features=self.conv5.out_channels)\n",
    "\n",
    "        # Define activation function based on user input\n",
    "        if self.activation.lower() == \"relu\":\n",
    "            self.activation_layer = nn.ReLU()\n",
    "        elif self.activation.lower() == \"gelu\":\n",
    "            self.activation_layer = nn.GELU()\n",
    "        elif self.activation.lower() == \"silu\":\n",
    "            self.activation_layer = nn.SiLU()\n",
    "        elif self.activation.lower() == \"mish\":\n",
    "            self.activation_layer = nn.Mish()\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Invalid activation function. Choose from 'relu', 'gelu', 'mish' or 'silu'\"\n",
    "            )\n",
    "\n",
    "        # Define max-pooling layers\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.dropout_layer = nn.Dropout(p=dropout)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        c1s = int(\n",
    "            (((img_size - self.kernel_size + (2 * self.padding)) / self.stride) + 1) / 2\n",
    "        )\n",
    "\n",
    "        c2s = int(\n",
    "            (((c1s - self.kernel_size + (2 * self.padding)) / self.stride) + 1) / 2\n",
    "        )\n",
    "\n",
    "        c3s = int(\n",
    "            (((c2s - self.kernel_size + (2 * self.padding)) / self.stride) + 1) / 2\n",
    "        )\n",
    "\n",
    "        c4s = int(\n",
    "            (((c3s - self.kernel_size + (2 * self.padding)) / self.stride) + 1) / 2\n",
    "        )\n",
    "\n",
    "        c5s = int(\n",
    "            (((c4s - self.kernel_size + (2 * self.padding)) / self.stride) + 1) / 2\n",
    "        )\n",
    "\n",
    "        # print(f\"c1s_{c1s}_c2s_{c2s}_c3s_{c3s}_c4s_{c4s}_c5s_{c5s}_out_{self.conv5.out_channels}\")\n",
    "\n",
    "        flatten_neurons = int(c5s * c5s * self.conv5.out_channels)\n",
    "\n",
    "        # print(f\"multi_{c5s*c5s*self.conv5.out_channels}_flat_{flatten_neurons}\")\n",
    "\n",
    "        # Define fully connected layers\n",
    "        self.fc1 = nn.Linear(flatten_neurons, dense_neurons)\n",
    "        self.fc2 = nn.Linear(dense_neurons, 10)\n",
    "        self.softmax_layer = nn.Softmax()\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Convolutional layers\n",
    "        x = self.conv1(x)\n",
    "        if self.batchnorm == \"Y\":\n",
    "            x = self.bn1(x)\n",
    "        x = self.activation_layer(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        if self.batchnorm == \"Y\":\n",
    "            x = self.bn2(x)\n",
    "        x = self.activation_layer(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        if self.usedropout == \"Y\":\n",
    "            x = self.dropout_layer(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        if self.batchnorm == \"Y\":\n",
    "            x = self.bn3(x)\n",
    "        x = self.activation_layer(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        if self.usedropout == \"Y\":\n",
    "            x = self.dropout_layer(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        if self.batchnorm == \"Y\":\n",
    "            x = self.bn4(x)\n",
    "        x = self.activation_layer(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        if self.usedropout == \"Y\":\n",
    "            x = self.dropout_layer(x)\n",
    "\n",
    "        x = self.conv5(x)\n",
    "        if self.batchnorm == \"Y\":\n",
    "            x = self.bn5(x)\n",
    "        x = self.activation_layer(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        # Flatten\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        if self.usedropout == \"Y\":\n",
    "            x = self.dropout_layer(x)\n",
    "\n",
    "        # Fully connected layers\n",
    "        x = self.fc1(x)\n",
    "        x = self.activation_layer(x)\n",
    "        x = self.fc2(x)\n",
    "        # x = self.softmax_layer(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, scores, y, accuracy = self._common_step(batch, batch_idx)\n",
    "\n",
    "        self.log_dict(\n",
    "            {\"train_loss\": loss, \"train_accuracy\": accuracy},\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "        )\n",
    "        return {\"loss\": loss, \"scores\": scores, \"y\": y}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, _, _, accuracy = self._common_step(batch, batch_idx)\n",
    "        self.log_dict(\n",
    "            {\"validation_loss\": loss, \"validation_accuracy\": accuracy},\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, scores, y, accuracy = self._common_step(batch, batch_idx)\n",
    "\n",
    "        self.log_dict(\n",
    "            {\"test_loss\": loss, \"test_accuracy\": accuracy},\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    def _common_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "\n",
    "        accuracy = 0\n",
    "\n",
    "        scores = self.forward(x)\n",
    "        loss = self.loss_fn(scores, y)\n",
    "        y_pred = torch.argmax(torch.softmax(scores, dim=1), dim=1)\n",
    "        accuracy += (y_pred == y).sum().item()\n",
    "        accuracy = accuracy / len(scores)\n",
    "        return loss, scores, y, accuracy\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "\n",
    "        scores = self.forward(x)\n",
    "        preds = torch.argmax(scores, dim=1)\n",
    "        return preds\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        if self.optimizer.lower() == \"adam\":\n",
    "\n",
    "            return optim.Adam(self.parameters(), lr=self.lr)\n",
    "\n",
    "        elif self.optimizer.lower() == \"sgd\":\n",
    "\n",
    "            return optim.SGD(self.parameters(), lr=self.lr)\n",
    "\n",
    "        elif self.optimizer.lower() == \"nadam\":\n",
    "\n",
    "            return optim.NAdam(self.parameters(), lr=self.lr)\n",
    "\n",
    "        elif self.optimizer.lower() == \"rmsprop\":\n",
    "\n",
    "            return optim.RMSprop(self.parameters(), lr=self.lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T15:39:30.145571Z",
     "iopub.status.busy": "2025-04-19T15:39:30.144937Z",
     "iopub.status.idle": "2025-04-19T15:40:02.134895Z",
     "shell.execute_reply": "2025-04-19T15:40:02.134252Z",
     "shell.execute_reply.started": "2025-04-19T15:39:30.145539Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: cako0b50\n",
      "Sweep URL: https://wandb.ai/cs23s025-indian-institute-of-technology-madras/CS23S025-Assignment-2-DL/sweeps/cako0b50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: j2ere8sw with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00394508348548209\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'CS23S025-Assignment-2-DL' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Ignoring entity 'cs23s025-indian-institute-of-technology-madras' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250419_153936-j2ere8sw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cs23s025-indian-institute-of-technology-madras/CS23S025-Assignment-2-DL/runs/j2ere8sw' target=\"_blank\">predictionTableRun</a></strong> to <a href='https://wandb.ai/cs23s025-indian-institute-of-technology-madras/CS23S025-Assignment-2-DL' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs23s025-indian-institute-of-technology-madras/CS23S025-Assignment-2-DL/sweeps/cako0b50' target=\"_blank\">https://wandb.ai/cs23s025-indian-institute-of-technology-madras/CS23S025-Assignment-2-DL/sweeps/cako0b50</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cs23s025-indian-institute-of-technology-madras/CS23S025-Assignment-2-DL' target=\"_blank\">https://wandb.ai/cs23s025-indian-institute-of-technology-madras/CS23S025-Assignment-2-DL</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/cs23s025-indian-institute-of-technology-madras/CS23S025-Assignment-2-DL/sweeps/cako0b50' target=\"_blank\">https://wandb.ai/cs23s025-indian-institute-of-technology-madras/CS23S025-Assignment-2-DL/sweeps/cako0b50</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cs23s025-indian-institute-of-technology-madras/CS23S025-Assignment-2-DL/runs/j2ere8sw' target=\"_blank\">https://wandb.ai/cs23s025-indian-institute-of-technology-madras/CS23S025-Assignment-2-DL/runs/j2ere8sw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged prediction table with 10 samples.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">predictionTableRun</strong> at: <a href='https://wandb.ai/cs23s025-indian-institute-of-technology-madras/CS23S025-Assignment-2-DL/runs/j2ere8sw' target=\"_blank\">https://wandb.ai/cs23s025-indian-institute-of-technology-madras/CS23S025-Assignment-2-DL/runs/j2ere8sw</a><br> View project at: <a href='https://wandb.ai/cs23s025-indian-institute-of-technology-madras/CS23S025-Assignment-2-DL' target=\"_blank\">https://wandb.ai/cs23s025-indian-institute-of-technology-madras/CS23S025-Assignment-2-DL</a><br>Synced 5 W&B file(s), 4 media file(s), 12 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250419_153936-j2ere8sw/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Function to log 2D Confusion Matrix\n",
    "def log_2d_confusion_matrix(cm, class_names):\n",
    "    fig = ff.create_annotated_heatmap(\n",
    "        z=cm, \n",
    "        x=class_names, \n",
    "        y=class_names,\n",
    "        colorscale = [[0, \"lightpink\"], [0.5, \"darkgoldenrod\"], [1, \"forestgreen\"]],\n",
    "        showscale=True\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        title=f\"2D Confusion Matrix\",\n",
    "        xaxis_title=\"Predicted Class\",\n",
    "        yaxis_title=\"Actual Class\",\n",
    "        autosize=True,\n",
    "        font=dict(size=14)\n",
    "    )\n",
    "    wandb.log({\"2D Confusion Matrix\": wandb.Html(fig.to_html())})\n",
    "\n",
    "# Function to log 3D Confusion Matrix\n",
    "def log_3d_confusion_matrix(cm):\n",
    "    fig_3d = go.Figure(data=[go.Surface(z=cm, \n",
    "                                       colorscale= [[0, \"pink\"], [0.5, \"darkgoldenrod\"], [1, \"green\"]])])\n",
    "    fig_3d.update_layout(\n",
    "        title=\"3D Confusion Matrix\",\n",
    "        scene=dict(\n",
    "            xaxis_title=\"Predicted Class\",\n",
    "            yaxis_title=\"Actual Class\",\n",
    "            zaxis_title=\"Count\"\n",
    "        ),\n",
    "        autosize=True,\n",
    "    )\n",
    "    wandb.log({\"3D Confusion Matrix\": wandb.Html(fig_3d.to_html())})\n",
    "\n",
    "# Sweep function to call logging\n",
    "def sweep_run():\n",
    "    wandb.init(\n",
    "        project=\"CS23S025-Assignment-2-DL\",\n",
    "        entity=\"cs23s025-indian-institute-of-technology-madras\",\n",
    "        name=\"predictionTableRun\",\n",
    "        notes=\"Logging prediction table and confusion matrix\",\n",
    "        tags=[\"prediction-table\", \"eval\", \"val-checkpoint\"]\n",
    "    )\n",
    "\n",
    "    # Define transformations\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    # Load validation dataset\n",
    "    val_dataset = ImageFolder(root=\"/kaggle/input/naturenew/inaturalist_12K/val\", transform=transform)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=wandb.config.batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    class_names = ['Amphibia', 'Animalia', 'Arachnida', 'Aves', 'Fungi', 'Insecta', 'Mammalia', 'Mollusca', 'Plantae', 'Reptilia']\n",
    "\n",
    "    # Load model\n",
    "    model = convNet.load_from_checkpoint(\n",
    "        checkpoint_path=\"/kaggle/input/macacccnn/pytorch/default/1/best_model.ckpt\",\n",
    "        img_size=256,\n",
    "        activation=\"gelu\",\n",
    "        num_filters=64,\n",
    "        filter_size=3,\n",
    "        filter_org=2,\n",
    "        stride=1,\n",
    "        padding=1,\n",
    "        dense_neurons=64,\n",
    "        learning_rate=wandb.config.learning_rate,\n",
    "        optimizer=\"adam\",\n",
    "        dropout=0.1,\n",
    "        usedropout=\"Y\",\n",
    "        batchnorm=\"Y\"\n",
    "    )\n",
    "\n",
    "    # Move the model to the correct device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    # Log prediction table\n",
    "    def log_prediction_table():\n",
    "        model.eval()\n",
    "        columns = [\"Image\", \"Actual Label\", \"Predicted Label\"]\n",
    "        prediction_table = wandb.Table(columns=columns)\n",
    "        num_samples = 10\n",
    "        samples_logged = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                if samples_logged >= num_samples:\n",
    "                    break\n",
    "\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                inputs_cpu = inputs.cpu()\n",
    "                labels_cpu = labels.cpu()\n",
    "                preds_cpu = preds.cpu()\n",
    "\n",
    "                for i in range(inputs_cpu.size(0)):\n",
    "                    if samples_logged >= num_samples:\n",
    "                        break\n",
    "\n",
    "                    img_tensor = inputs_cpu[i]\n",
    "                    true_label = class_names[labels_cpu[i].item()]\n",
    "                    pred_label = class_names[preds_cpu[i].item()]\n",
    "\n",
    "                    prediction_table.add_data(\n",
    "                        wandb.Image(img_tensor),\n",
    "                        true_label,\n",
    "                        pred_label\n",
    "                    )\n",
    "                    samples_logged += 1\n",
    "\n",
    "        if samples_logged > 0:\n",
    "            wandb.log({\"Prediction Table\": prediction_table})\n",
    "            print(f\"Logged prediction table with {samples_logged} samples.\")\n",
    "        else:\n",
    "            print(\"No samples were logged.\")\n",
    "\n",
    "    # Log confusion matrix\n",
    "    def log_confusion_matrix():\n",
    "        model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "        # Log 2D Confusion Matrix\n",
    "        log_2d_confusion_matrix(cm, class_names)\n",
    "\n",
    "        # Log 3D Confusion Matrix\n",
    "        log_3d_confusion_matrix(cm)\n",
    "\n",
    "    # Log creative prediction grid\n",
    "    def log_creative_prediction_grid(model, dataloader, class_names, device, num_images=30):\n",
    "        model.eval()\n",
    "        images_shown = 0\n",
    "        fig, axes = plt.subplots(10, 3, figsize=(12, 30))\n",
    "        axes = axes.flatten()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in dataloader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                for i in range(inputs.size(0)):\n",
    "                    if images_shown >= num_images:\n",
    "                        break\n",
    "\n",
    "                    img = inputs[i].cpu().permute(1, 2, 0).numpy()\n",
    "                    img = np.clip(img * 0.229 + 0.485, 0, 1)  # Unnormalize\n",
    "\n",
    "                    true_label = class_names[labels[i]]\n",
    "                    pred_label = class_names[preds[i]]\n",
    "\n",
    "                    correct = pred_label == true_label\n",
    "                    color = 'green' if correct else 'red'\n",
    "                    \n",
    "                    symbol = \"[✓]\" if correct else \"[✗]\"\n",
    "                    title = f\"{symbol} {true_label} → {pred_label}\"\n",
    "                    ax = axes[images_shown]\n",
    "                    ax.imshow(img)\n",
    "                    ax.set_title(title, color=color, fontsize=10, fontweight='bold')\n",
    "                    ax.axis('off')\n",
    "\n",
    "                    images_shown += 1\n",
    "\n",
    "                if images_shown >= num_images:\n",
    "                    break\n",
    "\n",
    "        plt.tight_layout()\n",
    "        wandb.log({\"Creative Prediction Grid\": wandb.Image(fig)})\n",
    "        plt.close()\n",
    "\n",
    "    # Call the logging functions\n",
    "    log_prediction_table()\n",
    "    log_confusion_matrix()\n",
    "    log_creative_prediction_grid(model, val_loader, class_names, device)\n",
    "    wandb.finish()\n",
    "\n",
    "# Sweep configuration with parameters\n",
    "sweep_config = {\n",
    "    \"name\": \"prediction-table-sweep-Final\",\n",
    "    \"metric\": {\"name\": \"validation_accuracy\", \"goal\": \"maximize\"},\n",
    "    \"method\": \"bayes\",\n",
    "    \"early_terminate\": {\"type\": \"hyperband\", \"min_iter\": 4, \"eta\": 2},\n",
    "    \"parameters\": {\n",
    "        \"learning_rate\": {\n",
    "            \"min\": 1e-5,\n",
    "            \"max\": 1e-2,\n",
    "            \"distribution\": \"uniform\"\n",
    "        },\n",
    "        \"batch_size\": {\n",
    "            \"values\": [16]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create the sweep\n",
    "sweep_id = wandb.sweep(sweep_config, entity=\"cs23s025-indian-institute-of-technology-madras\", project=\"CS23S025-Assignment-2-DL\")\n",
    "\n",
    "# Run the sweep agent\n",
    "wandb.agent(sweep_id, function=sweep_run, count=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART - B "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class wandbconfig:\n",
    "\n",
    "    def set_configs(args):\n",
    "\n",
    "        wandb_configs = {\n",
    "            \"epochs\": args.epochs,\n",
    "            \"img_size\": args.img_size,\n",
    "            \"dataug\": args.dataug,\n",
    "            \"batchnorm\": args.batchnorm,\n",
    "            \"num_filters\": args.num_filters,\n",
    "            \"filter_size\": args.filter_size,\n",
    "            \"filter_org\": args.filter_org,\n",
    "            \"batch_size\": args.batch_size,\n",
    "            \"learning_rate\": args.learning_rate,\n",
    "            \"dropout\": args.dropout,\n",
    "            \"usedropout\": args.usedropout,\n",
    "            \"optimizer\": args.optimizer,\n",
    "            \"dense_neurons\": args.dense_neurons,\n",
    "            \"activation\": args.activation,\n",
    "            \"stride\": args.stride,\n",
    "            \"padding\": args.padding,\n",
    "        }\n",
    "\n",
    "        return wandb_configs\n",
    "\n",
    "    def run_name(wandb_configs):\n",
    "\n",
    "        run_name = \"nf_{}_fsz_{}_fo_{}_a_{}_e_{}_b_{}_dn_{}_da_{}\".format(\n",
    "            wandb_configs[\"num_filters\"],\n",
    "            wandb_configs[\"filter_size\"],\n",
    "            wandb_configs[\"filter_org\"],\n",
    "            wandb_configs[\"activation\"],\n",
    "            wandb_configs[\"epochs\"],\n",
    "            wandb_configs[\"batch_size\"],\n",
    "            wandb_configs[\"dense_neurons\"],\n",
    "            wandb_configs[\"dataug\"],\n",
    "        )\n",
    "\n",
    "        return run_name\n",
    "\n",
    "    def sweep_name(wandb_configs):\n",
    "\n",
    "        sweep_name = \"nf_{}_fsz_{}_fo_{}_a_{}_e_{}_b_{}_dn_{}\".format(\n",
    "            wandb_configs.num_filters,\n",
    "            wandb_configs.filter_size,\n",
    "            wandb_configs.filter_org,\n",
    "            wandb_configs.activation,\n",
    "            wandb_configs.epochs,\n",
    "            wandb_configs.batch_size,\n",
    "            wandb_configs.dense_neurons,\n",
    "        )\n",
    "\n",
    "        return sweep_name\n",
    "\n",
    "    def tuner_set_configs(args):\n",
    "\n",
    "        wandb_configs = {\n",
    "            \"epochs\": args.epochs,\n",
    "            \"img_size\": args.img_size,\n",
    "            \"batch_size\": args.batch_size,\n",
    "            \"learning_rate\": args.learning_rate,\n",
    "            \"dropout\": args.dropout,\n",
    "        }\n",
    "\n",
    "        return wandb_configs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import lightning.pytorch as L\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "class iNaturalistDataModule(L.LightningDataModule):\n",
    "    def __init__(self, data_dir, batch_size, num_workers, img_size, data_augmentation):\n",
    "        super().__init__()\n",
    "\n",
    "        self.train_path = data_dir /\"train\"\n",
    "        self.test_path = data_dir /\"val\"\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "        if data_augmentation == \"Y\":\n",
    "\n",
    "            self.data_transform = transforms.Compose(\n",
    "                [\n",
    "                    transforms.Resize(size=(img_size, img_size)),\n",
    "                    transforms.AutoAugment(),  # This is the data augmentation method chosen\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(\n",
    "                        mean=[0.4712, 0.4600, 0.3896], std=[0.2034, 0.1981, 0.1948]\n",
    "                    ),  # These values are calculated for our dataset\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        elif data_augmentation == \"N\":\n",
    "\n",
    "            self.data_transform = transforms.Compose(\n",
    "                [\n",
    "                    transforms.Resize(size=(img_size, img_size)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(\n",
    "                        mean=[0.4712, 0.4600, 0.3896], std=[0.2034, 0.1981, 0.1948]\n",
    "                    ),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        self.test_data_transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize(size=(img_size, img_size)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(\n",
    "                    mean=[0.4748, 0.4645, 0.3965], std=[0.2004, 0.1954, 0.1923]\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def setup(self, stage):\n",
    "        if stage == \"fit\":\n",
    "\n",
    "            # First load all the training data\n",
    "            train_data_full = datasets.ImageFolder(\n",
    "                root=self.train_path,\n",
    "                transform=self.data_transform,\n",
    "                target_transform=None,\n",
    "            )\n",
    "\n",
    "            # Decide the number of validation samples required\n",
    "            validation_samples_per_class = int(0.2 * 1000)\n",
    "\n",
    "            # These lists will hold the indices of training and validation data samples\n",
    "            train_indices = []\n",
    "            val_indices = []\n",
    "\n",
    "            for class_idx in range(len(train_data_full.classes)):\n",
    "\n",
    "                # Obtain the indices of each class\n",
    "                class_indices = [\n",
    "                    idx\n",
    "                    for idx, (_, label) in enumerate(train_data_full.imgs)\n",
    "                    if label == class_idx\n",
    "                ]\n",
    "\n",
    "                # Split and add the indices to the respective lists\n",
    "                val_indices.extend(class_indices[:validation_samples_per_class])\n",
    "                train_indices.extend(class_indices[validation_samples_per_class:])\n",
    "\n",
    "            # Create a two subsets of the initially loaded training data as training data and validation data\n",
    "            self.train_data = Subset(train_data_full, train_indices)\n",
    "            self.val_data = Subset(train_data_full, val_indices)\n",
    "\n",
    "        if stage == \"test\":\n",
    "            # Load the test data\n",
    "            self.test_data = datasets.ImageFolder(\n",
    "                root=self.test_path, transform=self.test_data_transform\n",
    "            )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_data,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            persistent_workers=True,\n",
    "            shuffle=True,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_data,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            persistent_workers=True,\n",
    "            shuffle=False,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_data,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=False,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import lightning.pytorch as L\n",
    "import torchvision.models\n",
    "\n",
    "class efficientNet(L.LightningModule):\n",
    "\n",
    "    def __init__(self, dropout, learning_rate):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dropout = dropout\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        weights = torchvision.models.EfficientNet_V2_S_Weights.DEFAULT #We obtain the best available weights for this model\n",
    "        model = torchvision.models.efficientnet_v2_s(weights=weights) #Initializing the model\n",
    "\n",
    "        #We use the approach of overwriting the classifier layer, so that output classes is 10.\n",
    "        model.classifier = torch.nn.Sequential(\n",
    "        torch.nn.Dropout(p=dropout, inplace=True), \n",
    "        torch.nn.Linear(in_features=1280, \n",
    "                        out_features=10, #Here initially it was 1000\n",
    "                        bias=True))\n",
    "\n",
    "        #We are freezing all the features layers. This does not include freezing of the classifier layer.\n",
    "        for param in model.features.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.efNet_tuned = model\n",
    "\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.efNet_tuned(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, scores, y, accuracy = self._common_step(batch, batch_idx)\n",
    " \n",
    "        self.log_dict(\n",
    "            {\n",
    "                \"train_loss\": loss,\n",
    "                \"train_accuracy\": accuracy\n",
    "            },\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "        )\n",
    "        return {\"loss\": loss, \"scores\": scores, \"y\": y}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, scores, y, accuracy = self._common_step(batch, batch_idx)\n",
    "        self.log_dict(\n",
    "            {\n",
    "                \"validation_loss\": loss,\n",
    "                \"validation_accuracy\": accuracy\n",
    "            },\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, _, _, accuracy = self._common_step(batch, batch_idx)\n",
    "        self.log_dict(\n",
    "            {\n",
    "                \"test_loss\": loss,\n",
    "                \"test_accuracy\": accuracy\n",
    "            },\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    def _common_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        \n",
    "        accuracy = 0\n",
    "        scores = self.forward(x)\n",
    "        loss = self.loss_fn(scores, y)\n",
    "        y_pred = torch.argmax(torch.softmax(scores, dim=1), dim=1)\n",
    "        accuracy += (y_pred == y).sum().item()\n",
    "        accuracy = accuracy/len(scores)\n",
    "        return loss, scores, y, accuracy\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "        \n",
    "        scores = self.forward(x)\n",
    "        preds = torch.argmax(scores, dim=1)\n",
    "        return preds\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "         return optim.Adam(self.parameters(), lr=self.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import argparse\n",
    "import wandb\n",
    "from types import SimpleNamespace\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.fabric.utilities.seed import seed_everything\n",
    "from pathlib import Path\n",
    "\n",
    "# from efficientNet_v2 import efficientNet\n",
    "# from dataset import iNaturalistDataModule\n",
    "# from wandbConfigs import wandbconfig\n",
    "\n",
    "device = \"gpu\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "seed_everything(42)\n",
    "\n",
    "\n",
    "def train(wandb_configs, args):\n",
    "\n",
    "    # Initialise wandb\n",
    "    run_name = \"EfficientNetV2_Freeze_All-Final\"\n",
    "    wandb.init(\n",
    "        config=wandb_configs,\n",
    "        project=args.wandb_project,\n",
    "        entity=args.wandb_entity,\n",
    "        name=run_name,\n",
    "    )\n",
    "    wandb_logger = WandbLogger(project=args.wandb_project)\n",
    "    wandb_configs = wandb.config\n",
    "\n",
    "    model = efficientNet(0.2, 0.001)\n",
    "\n",
    "    data = iNaturalistDataModule(\n",
    "        data_dir=Path(args.path),\n",
    "        batch_size=wandb_configs.batch_size,\n",
    "        num_workers=2,\n",
    "        img_size=wandb_configs.img_size,\n",
    "        data_augmentation=\"N\",\n",
    "    )\n",
    "    trainer = Trainer(\n",
    "        accelerator=device,\n",
    "        min_epochs=1,\n",
    "        max_epochs=wandb_configs.epochs,\n",
    "        logger=wandb_logger,\n",
    "        log_every_n_steps=50,\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, data)\n",
    "    trainer.validate(model, data)\n",
    "    # trainer.test(model, data)\n",
    "\n",
    "    wandb.finish()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    args = SimpleNamespace(\n",
    "    wandb_project=\"CS23S025-Assignment-2-DL\",\n",
    "    wandb_entity=\"cs23s025-indian-institute-of-technology-madras\",\n",
    "    path=\"/kaggle/input/naturenew/inaturalist_12K\",\n",
    "    epochs=15,\n",
    "    img_size=224,\n",
    "    batch_size=64,\n",
    "    learning_rate=0.001,\n",
    "    dropout=0.1,\n",
    "    )\n",
    "\n",
    "    # Get wandb configs\n",
    "    wandb_configs = wandbconfig.tuner_set_configs(args)\n",
    "    \n",
    "    # Run training\n",
    "    train(wandb_configs, args)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7154606,
     "sourceId": 11423999,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7184888,
     "sourceId": 11465495,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 310024,
     "modelInstanceId": 289283,
     "sourceId": 346241,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
